
                    <span class="notifications" id="user-notifications"></span>
                    <div role="main"><span id="maincontent"></span><h2>Лекция 12</h2><div class="navtop border-top py-3 clearfix navimages"><a title="Закрыть книгу" class="bookexit" href="https://edu.vsu.ru/course/view.php?id=3401#section-6"><i class="icon fa fa-arrow-up fa-fw " title="Закрыть книгу" aria-label="Закрыть книгу"></i></a></div><div class="box py-3 generalbox book_content"><h3>1. Основы кластерного анализа в рамках статистического и детерминистского подходов</h3><div class="no-overflow"><div class="Section1">
<p class="MsoNormal" style="text-indent: 42.55pt; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Задача кластеризации </span><span style="font-size: 16.0pt; line-height: 125%;">состоит в разбиении множества объектов, представленных своими образами, на кластеры, в каждом из которых объединяются в известном смысле «близкие» образы, в то время как образы, помещаемые в различные кластеры, имеют существенные «отличия». </span></p>
<p class="MsoNormal" style="text-indent: 42.55pt; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Кластер (</span><span class="w"><span style="font-size: 16.0pt; line-height: 125%; color: black;">англ</span></span><span style="font-size: 16.0pt; line-height: 125%; color: black;">. <span class="w">cluster</span>&nbsp;— <span class="w">гроздь</span>, <span class="w">скопление</span>) – группа <span class="w">однотипных объектов, имеющих определенную степень близость в пространстве используемых для их описания признаков</span>. </span></p>
<p class="MsoNormal" style="text-indent: 42.55pt; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Кластеризация по определению осуществляется в режиме самообучения (без учителя). В лучшем случае, изначально может быть задано количество&nbsp; кластеров, на которые следует разделить образы. Но часто и подобная информация отсутствует. </span></p>
<p class="MsoNormal" style="text-indent: 42.55pt; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Существенно, также, и то, что каждая группа должна содержать образы с такими общими признаками, которые позволяет рассматривать их как принадлежащие некоторому порождающему классу образов. Иными словами кластеры должны отражать сущности, обладающие общими категориальными свойствами. Поэтому эту задачу еще называют задачей классификацией без обучения.</span></p>
<p class="MsoBodyText" style="text-align: justify;"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">Помимо этих терминов, в литературе встречается термин таксономия, который обозначает задачу разбиения и систематизации объектов по таксонам.</span><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;"> Таксо́н </span><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">(от <a href="https://ru.wikipedia.org/wiki/%D0%94%D1%80%D0%B5%D0%B2%D0%BD%D0%B5%D0%B3%D1%80%D0%B5%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D1%8F%D0%B7%D1%8B%D0%BA" title="Древнегреческий язык"><span style="color: windowtext;">др.-греч.</span></a> «порядок, устройство, организация»)&nbsp;— группа, состоящая из дискретных объектов, объединяемых на основании общих свойств и признаков. Классифицирующие системы, использующие понятие «таксона», обычно носят <i>иерархический</i> характер, т.е. разбиение объектов на группы представляется в порядке от более мелких к более крупным (или наоборот). Суть задачи таксономии хорошо просматривается при систематизации объектов в биологии.</span></p>
<p class="MsoBodyText" style="text-align: justify;"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">Задача обучения без учителя в интересах кластерного анализа данных, особенно в ситуации отсутствия априорной информации о числе кластеров, является, безусловно, сложнейшей в ряду всех рассмотренных. Она может решаться как в рамках статистического, так и в рамках детерминистского подходов. </span></p>
<p class="MsoBodyText" style="text-align: justify;"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">&nbsp;</span></p>
<p class="MsoBodyTextIndent" align="center" style="margin-left: 0cm; text-align: center; text-indent: 0cm;"><b><span style="font-size: 16.0pt; line-height: 125%;">1.<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></b><b><span style="font-size: 16.0pt; line-height: 125%;">Статистический подход к задаче классификации без обучения&nbsp; &nbsp;(</span></b><b><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">EM</span></b><b><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;"> </span></b><b><span style="font-size: 16.0pt; line-height: 125%;">– алгоритм)</span></b></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">В рамках статистического подхода рассматривается задача обучения без учителя, напрямую связанная с задачей кластеризации. Рассмотрим первоначально следующую постановку этой задачи.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">1.Пусть имеется не помеченная, смешанная обучающая выборка образов <sub><img border="0" width="222" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image001.gif"></sub>, принадлежащих <sub><img border="0" width="24" height="18" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image002.gif"></sub>различным классам, которые далее будем называть порождающими.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">2. Число порождающих классов <sub><img border="0" width="24" height="18" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image002.gif"></sub>считается известным, при этом априорные вероятности появления наблюдений каждого класса <sub><img border="0" width="206" height="30" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image003.gif"></sub>&nbsp;неизвестны.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">3. Считается известным или вводится обоснованнее предположение относительно вида плотностей распределения классов <sub><img border="0" width="264" height="30" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image004.gif"></sub>, где <sub><img border="0" width="134" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image005.gif"></sub>&nbsp;&nbsp;векторы неизвестных параметров плотностей распределений классов.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Требуется оценить общий набор неизвестных параметров&nbsp; как составной вектор вида <sub><img border="0" width="186" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image006.gif"></sub>, т.е. произвести оценку параметров смеси распределений вида</span></p>
<p class="MsoBodyTextIndent" align="right" style="text-align: right;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="241" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image007.gif"></sub>.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Далее по результатам оценки векторного параметра смеси необходимо произвести индексацию образов <sub><img border="0" width="144" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image008.gif"></sub>, привязав каждый из них к одной из компонент смеси, т.е. провести классификацию без учителя.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Задача может быть решена, если плотность распределения <sub><img border="0" width="60" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image009.gif"></sub>&nbsp;в (1) существует и идентифицируема, т.е. если из <sub><img border="0" width="47" height="21" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image010.gif"></sub>следует, что <sub><img border="0" width="137" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image011.gif"></sub>. На практике большинство смесей идентифицируемы, в том числе и смеси гауссовских распределений, с которыми, в основном, и работают при проведении оценок параметров в задаче классификации без обучения. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Итак, пусть смесь идентифицируема. Представим функцию правдоподобия выборки в виде</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="329" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image012.gif"></sub>.</span></p>
<p class="MsoBodyText" style="text-align: justify;"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">Как и ранее, при решении задач оценивания параметров, задача может быть решена на основе двух базовых подходов, а именно: подхода, основанного на методе максимального правдоподобия, и байесовского подхода, базирующегося на методе максимума апостериорной вероятности. При использовании метода максимального правдоподобия оцениваемые параметры рассматриваются как фиксированные и неизвестные. При использовании метода максимума апостериорной вероятности оцениваемые параметры рассматриваются как случайные величины, для которых должно быть задано априорное распределение. Мы остановимся на&nbsp; первом варианте решения задачи, учитывая, что получаемые результаты при применении указанных подходов в большинстве практически значимых случаев достаточно близки.</span></p>
<p class="MsoBodyText" style="text-align: justify;"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">При использовании метода максимального правдоподобия оценка </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="15" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image013.gif"></sub>&nbsp;</span><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;">формально может быть найдена&nbsp; как точка в многомерном пространстве, которая максимизирует логарифм функции правдоподобия</span></p>
<p class="MsoBodyText"><span style="font-size: 16.0pt; line-height: 125%; font-weight: normal;"><sub><img border="0" width="260" height="45" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image014.gif"></sub>,</span></p>
<p class="MsoNormal" style="text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">где сумма по неизвестным значениям априорных вероятностей классов играет роль ограничения к оптимизационной задаче. Решение подобной задачи в лоб в силу ее громоздкости практически невозможно. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Поэтому наибольшее распространение получил подход, основанный на реализации итерационных процедур поиска оптимального решения, которые называются алгоритмами <span style="color: #2d2d2d;">максимизации математического ожидания</span> или </span><span style="font-size: 16.0pt; line-height: 125%;">EM - алгоритмами (expectation - maximization). Особенностью этих алгоритмов является использование </span><span style="font-size: 16.0pt; line-height: 125%; color: black;">вспомогательной совокупности скрытых переменных <sub><img border="0" width="19" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image015.gif"></sub>. Скрытые переменные рассматриваются как наблюдаемые параметры и вводятся таким образом, чтобы их можно было вычислить при условии задания вектора&nbsp; </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="187" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image016.gif"></sub>. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Это позволяет свести сложную оптимизационную задачу к последовательности итераций по пересчету скрытых переменных на основе текущего приближения вектора оцениваемых параметров (E-шаг) и максимизации правдоподобия с целью найти следующее приближение (М-шаг). </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Дополняющий вектор скрытых переменных вводится таким образом, чтобы на его основе можно было бы упростить максимизацию функции </span><span style="font-size: 16.0pt; line-height: 125%;">правдоподобия.<span style="color: black;"> Поскольку неизвестно, какой именно компонентой смеси распределений порожден каждый образ, для обозначения этого факта введем индексы </span><sub><img border="0" width="148" height="30" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image017.gif"></sub><span style="color: black;">, значения которых для нас скрыты. Здесь </span><sub><img border="0" width="45" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image018.gif"></sub><span style="color: black;">, если </span><sub><img border="0" width="63" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image019.gif"></sub>&nbsp;и <sub><img border="0" width="48" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image020.gif"></sub><span style="color: black;">, если </span><sub><img border="0" width="61" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image021.gif"></sub>. Именно эти индексы являются отражением скрытых параметров, оценку которых можно получить, зная компоненты смесей. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Удобно, в<span style="color: black;"> качестве скрытых переменных, однозначно вычисляемых при известном виде функций правдоподобия классов, рассматривать апостериорные математические ожидания этих индексов. Они определяются вероятностями </span><sub><img border="0" width="83" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image022.gif"></sub>&nbsp;<span style="color: black;">того, что образ </span><sub><img border="0" width="29" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image023.gif"></sub>порожден классом <sub><img border="0" width="21" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image024.gif"></sub>&nbsp;(получен из компонента смеси&nbsp; с параметрами <sub><img border="0" width="19" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image025.gif"></sub>). Тогда соответствующее значение скрытой переменной при заданном значении <sub><img border="0" width="15" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image026.gif"></sub>&nbsp;рассчитывается как</span></p>
<p class="MsoNormal" align="right" style="text-align: right; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;"><sub><img border="0" width="69" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image027.gif"></sub></span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="152" height="71" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image028.gif"></sub>,&nbsp;&nbsp; <sub><img border="0" width="132" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image029.gif"></sub>,<span style="color: black;"><sub><img border="0" width="69" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image027.gif"></sub>.</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (2)</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Существо действий выполняемых на <span style="color: black;">E-шаге и М-шаге алгоритма наглядно можно пояснить на примере оценки смеси гауссовских распределений с неизвестными математическими ожиданиями и матрицами ковариациями</span></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="284" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image030.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><b><span style="font-size: 16.0pt; line-height: 125%;">EM -&nbsp; алгоритм (стандартная реализация) по шагам</span></b><span style="font-size: 16.0pt; line-height: 125%;">:</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">1. Вводится начальное значение (начальное приближение)&nbsp; <sub><img border="0" width="189" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image031.gif"></sub>, <sub><img border="0" width="163" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image032.gif"></sub>&nbsp;и начальные значения <sub><img border="0" width="49" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image033.gif"></sub>, <sub><img border="0" width="125" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image034.gif"></sub>. Для генерации начальной точки могут использоваться эвристические процедуры, основанные на любых разумных предположениях. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;Далее в цикле, охватывающем последующие пункты, осуществляются следующие действия. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">2. Выполняется E-шаг, в ходе которого рассчитываются условные математические ожидания скрытых переменных (вероятностей их единичных значений)</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="182" height="73" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image035.gif"></sub>,&nbsp; <sub><img border="0" width="125" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image034.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">3. Выполняется M-шаг, в ходе которого проводится перерасчет предыдущего приближения <sub><img border="0" width="189" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image031.gif"></sub>так, чтобы максимизировать правдоподобие наблюдений&nbsp; <b><sub><img border="0" width="184" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image036.gif"></sub>&nbsp;</b>при ограничении<b> <sub><img border="0" width="75" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image037.gif"></sub>. </b>Перерасчет проводится с учетом вычисленных значений <sub><img border="0" width="28" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image038.gif"></sub>следующим образом:</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><b><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="137" height="48" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image039.gif"></sub>,&nbsp;&nbsp; <sub><img border="0" width="129" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image040.gif"></sub>, <sub><img border="0" width="260" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image041.gif"></sub>. </span></b></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">4. Если разница значений скрытых переменных на соседних шагах <sub><img border="0" width="183" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image042.gif"></sub>, то осуществляется присвоение <sub><img border="0" width="60" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image043.gif"></sub>, <sub><img border="0" width="126" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image044.gif"></sub>&nbsp;<sub><img border="0" width="126" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image044.gif"></sub>&nbsp;и переход на следующий шаг цикла в п. 2. Иначе ­– останов. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">В п.4. <sub><img border="0" width="20" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image045.gif"></sub>&nbsp;– порог для фиксации останова итеративного процесса пересчета параметров при условии незначительности изменения скрытых переменных.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Можно показать, что вычисления, выполняемые на M-шаге, эквивалентны независимому определению необходимого условия максимума логарифмов функций правдоподобия, рассчитываемых с весами </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="24" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image046.gif"></sub>, <sub><img border="0" width="125" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image034.gif"></sub></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><b><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="233" height="48" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image047.gif"></sub>.</span></b></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Также очевидно, что если апостериорные вероятности принимают значения 0 и 1, определяя однозначно принадлежность каждого образа тому или иному классу,&nbsp; то задача сводится к ранее рассмотренной задаче оценки параметров плотностей распределений классов по индексированным выборкам.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Качество решения и скорость сходимости EM-алгоритма существенно зависят от начального приближения. Стандартный прием, позволяющий частично преодолеть эту зависимость заключается в том, чтобы несколько раз повторить процесс оценивания, задавая каждый раз начальные значения параметров смеси случайным образом. В итоге выбирается тот результат, который будет наилучшим по заданному критерию, например, по максимуму правдоподобия наблюдений.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;Другой прием состоит в том, чтобы взять в качестве центров компонент </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub></span><span style="font-size: 16.0pt; line-height: 125%;">объектов, максимально удалённых друг от друга. Для этой цели может использоваться так называемый </span><span style="font-size: 16.0pt; line-height: 125%;">максиминный алгоритм назначения центров. Он состоит в следующем. Первые два центра выделяются на основе нахождения максимума среди всех вычисляемых попарно расстояний между образами исходной выборки. Каждый следующий центр выбирается так, чтобы минимальное расстояние от назначаемого в качестве этого центра образа от него до ранее найденных центров было бы максимальным среди всех образов (образ является наиболее удаленным от ранее найденных центров).</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Фактически в&nbsp; результате выполнения EM- алгоритма мы получаем весовые коэффициенты, характеризующие степень принадлежности образов тому или иному порождающему классу. Поэтому, в итоге, можно выполнить отнесение каждого образа обучающей выборки к группе, обозначаемой как </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="24" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image049.gif"></sub>,<span style="color: black;"> в соответствии с максимальным значением</span></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="275" height="39" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image050.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">В этом и состоит связь задачи самообучения для смеси распределений классов и задачи кластеризации.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Существуют модификации рассмотренного выше EM-алгоритма. К ним относится так называемый статистический ЕМ - алгоритм (</span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">SEM</span><span style="font-size: 16.0pt; line-height: 125%;"> – алгоритм). В его основе лежит замена максимизации взвешенных логарифмов функций правдоподобия компонентов смеси максимизацией логарифмов функций правдоподобия, вычисляемыми по случайно выбранным подмножествам исходной выборки, которые формируются путем розыгрыша вероятностей <sub><img border="0" width="24" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image046.gif"></sub>, <sub><img border="0" width="125" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image034.gif"></sub>. Известны медианные модификации <span class="mw-headline"><span style="color: black;">ЕМ-алгоритма, в которых </span></span><span style="color: black;">моментные оценки максимального правдоподобия заменяются более </span><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%BE%D0%B1%D0%B0%D1%81%D1%82%D0%BD%D0%BE%D0%B5_%D0%BE%D1%86%D0%B5%D0%BD%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5" title="Робастное оценивание"><span style="color: windowtext;">устойчивыми (робастными) оценками</span></a> <a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D0%B4%D0%B8%D0%B0%D0%BD%D0%B0_%28%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0%29" title="Медиана (статистика)"><span style="color: windowtext;">медианного</span></a> типа.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">На основе разработанной в среде M</span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">atlab</span><span style="font-size: 16.0pt; line-height: 125%;"> программы проводилось тестирование алгоритма для данных различных примеров, позволяющее продемонстрировать возможности алгоритма.&nbsp;&nbsp; В ходе моделирования </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">EM</span><span style="font-size: 16.0pt; line-height: 125%;"> - алгоритма исследовался вопрос зависимости качества его работы от величины dm, характеризующей степень пересекаемости компонентов смесей, объема обучающих данных,&nbsp; а также от различных значениях объема выборки <sub><img border="0" width="20" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image051.gif"></sub>. При проведении моделирования рассматривались два примера, отличающиеся вариантами задания исходных данных, определяющих конфигурацию кластеров: </span><span style="font-size: 16.0pt; line-height: 125%;">первый пример </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="43" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image052.gif"></sub>; <sub><img border="0" width="52" height="18" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image053.gif"></sub>, центры кластеров расположены в вершинах квадрата со сторонами dm;</span><span style="font-size: 16.0pt; line-height: 125%;">&nbsp; второй пример&nbsp; </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="49" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image054.gif"></sub>; <sub><img border="0" width="51" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image055.gif"></sub>, центры каждого кластера генерируютсяслучайным образом по равномерному закону&nbsp; dm*rand(n,1) с фиксированным сдвигом DM=2. <span style="color: black;">&nbsp;&nbsp;&nbsp;&nbsp;</span></span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">На рис.1 представлены результаты визуализации различных этапов анализа данных для первого примера</span><span style="font-size: 16.0pt; line-height: 125%;">. Здесь на рис.1а приведена локализация исходной смешанной выборки данных с наложенными на нее линиями постоянного уровня получаемой модели смеси, на рис.1b&nbsp; приведено отображение уровней вероятностей принадлежности данных компонентам смеси данных <span style="color: black;"><sub><img border="0" width="69" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image027.gif"></sub>, а на рис.1,в – результаты классификации, полученные при разметке данных.</span> </span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image056.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image057.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">а)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">б)</span><span style="font-size: 16.0pt; line-height: 125%;"> </span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image058.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">в)</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.1. Визуализация различных этапов анализа данных для 4 кластеров</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">На рис.2,а,б,в,г приведены зависимости частости ошибок от величины dm для двух вариантов построения EM – алгоритма, отличающихся различной величиной порога, определяющего завершение итеративного процесса уточнения параметров смеси. Зависимости на рис.2,а,г представлены для первого примера задания данных при Ni=500 (а) и Ni=50 (б)</span><span style="font-size: 16.0pt; line-height: 125%;">, определяющих конфигурацию кластеров. </span><span style="font-size: 16.0pt; line-height: 125%;">Зависимости на рис.2,в,г даны для второго примера задания данных,</span><span style="font-size: 16.0pt; line-height: 125%;"> определяющих конфигурацию кластеров при тех же значениях количества образов, представляющих каждый кластер.</span><span style="font-size: 16.0pt; line-height: 125%;"> Параметр H определяет количество проводимых экспериментов при тестировании и усреднении результатов кластеризации.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image059.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image060.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">а)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">б)</span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;"> </span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image061.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image062.jpg"></span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">в)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; г)</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.2. Результаты тестирования алгоритма&nbsp; для различных вариантов исходных данных</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">На приведенных графиках видно вполне естественное убывание уровня ошибок при увеличении параметра dm, которое в большей степени проявляется для первого примера. Следует также отметить, что при запуске программы при малых объемах выборки необходимо включать режим регуляризации, так как в этом случае велика вероятность получения в процессе выполнения итераций плохо обусловленных матриц. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Таким образом, мы видим, что в рамках статистического подхода задача кластеризации сводится к задаче оценивания параметров смеси распределений в гауссовском представлении. Такая кластеризация опирается на полученное решение, используя рассчитанные значения вероятностей принадлежности каждого образа выделенным компонентам смеси.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Исследованный здесь алгоритм не учитывает одну важную и часто встречающуюся на практике ситуацию: отсутствие информации о количестве порождающих классов. Для решения задачи в такой постановке существуют различные подходы, в том числе представленные в модификациях EM-алгоритма. Базовый подход основан на использовании специальных алгоритмов получения оценок числа классов при выполнении последовательности нескольких кластеризаций с разным значением </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="24" height="18" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image002.gif"></sub><span style="color: black;">. Далее он будет рассмотрен и исследован в ходе сравнительного анализа различных алгоритмов, включая и EM- алгоритм.</span></span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">&nbsp;</span></p>
<p class="MsoBodyTextIndent" align="center" style="margin-left: 0cm; text-align: center; text-indent: 0cm;"><b><span style="font-size: 16.0pt; line-height: 125%;">2.<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></b><b><span style="font-size: 16.0pt; line-height: 125%;">Детерминистский подход к задаче классификации без обучения. Критерии оптимальности разбиения данных на кластеры&nbsp; &nbsp;</span></b></p>
<p class="MsoBodyTextIndent" style="text-indent: 0cm;"><b><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></b></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">В рамках детерминистского подхода задача кластеризации формулируется следующим образом.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">1. Имеется не помеченная, смешанная обучающая выборка образов <sub><img border="0" width="221" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image063.gif"></sub>, принадлежащих <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>различным порождающим классам.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">2. Число порождающих классов <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>&nbsp;может быть, как известно, так и не известно. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">3. Заданы функции расстояния (меры близости) <sub><img border="0" width="87" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image064.gif"></sub>, дающие возможность судить о степени сходства образов в признаковом пространстве.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Требуется в соответствии с заданным критерием оптимальности выполнить разбиение <sub><img border="0" width="163" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image065.gif"></sub>&nbsp;смешанной выборки образов на группы <sub><img border="0" width="229" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image066.gif"></sub>, обладающие следующими свойствами:</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="131" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image067.gif"></sub>,&nbsp;&nbsp;&nbsp; <sub><img border="0" width="96" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image068.gif"></sub>,&nbsp;&nbsp;&nbsp;&nbsp; <sub><img border="0" width="85" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image069.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Следует сразу отметить, что такая постановка предусматривает реализацию исключительно однозначной (четкой) процедурой разбиения выборки на группы. Она является стандартной, но не единственной, так как в подобных задачах иногда лучше отказаться от однозначного ответа при привязке образа к кластеру (нечеткая кластеризация). Тем не менее, далее мы будем придерживаться именно этой постановки задачи.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Решением задачи, как уже сказано, является такое разбиение, которое удовлетворяет некоторому критерию оптимальности. Этот критерий должен отражать уровень желательности различных вариантов разбиений и выполненной кластеризации в целом. </span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">При не известном значении <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>единый строго обоснованный критерий оптимальности отсутствует и задача является некорректно поставленной. &nbsp;Это, однако, не означает, что нельзя использовать эвристические критерии, пригодные для получения решений в конкретных ситуациях. При обосновании подобных критериев могут использоваться различные показатели, вычисляемые для каждого возможного разбиения <sub><img border="0" width="29" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image070.gif"></sub>. </span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">В этом плане, одним из основных показателей, используемых для определения качества кластеризации, является среднее суммы квадратов расстояния образов каждого кластера до его центра – внутриклассовый разброс (ВР), рассчитываемый как</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="241" height="45" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image071.gif"></sub>,&nbsp;&nbsp; <sub><img border="0" width="177" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image072.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">При использовании в качестве функции расстояния Евклидовой метрики данная величина выражается через матрицы рассеяния классов </span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="235" height="47" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image073.gif"></sub>, <sub><img border="0" width="233" height="46" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image074.gif"></sub>,</span></p>
<p class="MsoBodyTextIndent" align="left" style="text-align: left; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;">где <sub><img border="0" width="87" height="30" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image075.gif"></sub>&nbsp;­– матрицы рассеяния образов каждого кластера.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;Если число порождающих классов известно, оптимальным разбиением по данному показателю часто считается то, которое минимизирует </span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="157" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image076.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Такой подход называется группированием с минимальной дисперсией. Данный критерий хорошо работает в случаях, когда порождающие классы образуют компактные, хорошо локализованные друг относительно друга кластеры. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">При неизвестном числе классов величина <sub><img border="0" width="103" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image077.gif"></sub>&nbsp;будет монотонно уменьшаться с увеличением числа групп разбиения, доходя до нижней границы, равной нулю при разбиении на группы, содержащие по одному образу. Это означает, что напрямую этот показатель в данной ситуации не может быть использован.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Еще один важный показатель, фигурирующий в подобных задачах, основан на вычислении средней суммы квадратов расстояний между центрами кластеров относительно общего центра. Он характеризует межклассовый разброс (MР), рассчитываемый как</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="225" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image078.gif"></sub>,&nbsp;&nbsp; <sub><img border="0" width="175" height="47" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image079.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">При использовании в качестве функции расстояния Евклидовой метрики МР выражается через матрицу рассеяния между классами </span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="148" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image080.gif"></sub>, <sub><img border="0" width="217" height="44" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image081.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Принципиально то, что общая матрица рассеяния данных исходной выборки, независимо от разбиения, представляется в виде </span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="449" height="45" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image082.gif"></sub></span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="611" height="45" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image083.gif"></sub></span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="76" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image084.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Это означает, что применение любого разбиения на кластеры не изменяет величины следа общей матрицы рассеяния <sub><img border="0" width="138" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image085.gif"></sub>, которая в данном случае является инвариантом относительно разбиения <sub><img border="0" width="33" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image086.gif"></sub>. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Существование подобного инварианта позволяет надеяться на возможность формирования такого критерия качества кластеризации, который буде гарантировать определение разумного разбиения исходной выборки. Действительно, при увеличении количества групп величина <sub><img border="0" width="152" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image087.gif"></sub>&nbsp;уменьшается, но при этом обязательно будет увеличиваться величина <sub><img border="0" width="148" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image080.gif"></sub>. Это потенциально позволит регуляризировать решение и избежать появления заведомо неприемлемого. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;Существует много&nbsp; подходов и конкретных алгоритмов кластеризации, которые подробно рассмотрены в ранее упомянутых источниках. К ним относятся, например,&nbsp; подходы, основанные на выполнении итеративной оптимизации процесса разбиения данных на группы; подходы, основанные на иерархическом представлении процесса формирования групп; подходы, опирающиеся на графовые описания задачи, и многие другие. Далее мы ограничимся рассмотрением двух базовых алгоритмов в условиях известного и не неизвестного числа классов.</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><b><span style="font-size: 16.0pt; line-height: 125%;">3. Кластеризация при известном числе классов. Алгоритм K- внутригрупповых средних и алгоритм иерархической кластеризации</span></b></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Рассмотрим ситуацию, когда число классов заранее известно. В этом случае задача существенно упрощается&nbsp; и становится корректно поставленной задачей дискретной оптимизации. При ее решении требуется перебрать все возможные комбинации разбиения и использовать критерий, отражающий качество получаемого результата, например, минимума внутриклассового разброса (кластеризация с минимальной дисперсией). Очевидно, также, что прямой перебор всех комбинаций слишком затратен и нужен другой, более разумный способ нахождений решения, которое будет близко к оптимальному. Рассмотренные ниже алгоритмы и представляют два возможных альтернативных варианта решения задачи кластеризации при заданном числе классов. </span></p>
<p class="MsoBodyTextIndent"><b><span style="font-size: 16.0pt; line-height: 125%;">Алгоритм K-внутригрупповых средних (K – means).</span></b><span style="font-size: 16.0pt; line-height: 125%;"> &nbsp;Далее имеется в виду, что <sub><img border="0" width="57" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image088.gif"></sub>– заданное число кластеров.<b> </b>В основе алгоритма лежит процедура объединения данных в группы с минимальной дисперсией, т.е. минимизация показателя <sub><img border="0" width="103" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image077.gif"></sub>. Алгоритм реализует итеративную оптимизацию критерия, которая отражает процесс направленного поиска решения. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Следует отметить, что при таком поиске глобально оптимальное решение может быть не найдено, а вместо него может быть получено локально оптимальное решение, т.е. найден локальный минимум функции критерия. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Идея алгоритма состоит в нахождении некоторого приемлемого начального разбиения данных на группы и выполнении нескольких итераций (шагов), на каждой из которых производится передвижение образов из одной группы в другую с одновременным пересчетом функции критерия и проведением контроля за изменениями ее значения. При этом на каждом шаге сохраняются такие перемещения, которые приводят к уменьшению значения <sub><img border="0" width="103" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image077.gif"></sub>. </span></p>
<p class="MsoBodyTextIndent"><b><span style="font-size: 16.0pt; line-height: 125%;">Алгоритм K – means (стандартная реализация) по шагам: </span></b></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">1. Выбираются начальные значения <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>&nbsp;центров кластеров <sub><img border="0" width="84" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image089.gif"></sub>, в качестве которых назначаются либо первые образы из исходной выборки<sub><img border="0" width="31" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image090.gif"></sub>(т.е. фактически случайно), либо <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>&nbsp;наиболее удаленных друг от друга образов выборки (максиминный алгоритм).</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Далее в цикле, охватывающем последующие пункты, осуществляются следующие действия.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">2. Проводится разбиение <sub><img border="0" width="155" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image091.gif"></sub>&nbsp;исходной выборки&nbsp; на кластеры, в ходе которого принадлежность каждого образа определяется на основе поиска минимума среди расстояний до установленных ранее центров <sub><img border="0" width="91" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image092.gif"></sub>. Рассчитывается начальное значение <sub><img border="0" width="103" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image077.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">3. Проводится перерасчет центров с учетом результатов выполненной в п.2 кластеризации </span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="177" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image093.gif"></sub></span></p>
<p class="MsoBodyTextIndent" align="left" style="text-align: left; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;">и соответствующий перерасчет функции <sub><img border="0" width="107" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image094.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">4. Если разница значений&nbsp; центров на соседних шагах <sub><img border="0" width="180" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image095.gif"></sub>, то осуществляется присвоение <sub><img border="0" width="57" height="26" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image096.gif"></sub>, <sub><img border="0" width="59" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image097.gif"></sub>&nbsp;и переход к выполнению следующего шага в п. 2. Иначе ­– останов.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">В п.4. <sub><img border="0" width="20" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image045.gif"></sub>&nbsp;– порог для фиксации останова итеративного процесса пересчета при условии незначительности изменения центров кластеров на соседних шагах.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Можно показать, что при реализации подобной процедуры значения функции <sub><img border="0" width="221" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image098.gif"></sub>&nbsp;не увеличиваются на соседних шагах и алгоритм сходится за конечное число шагов. Это означает, что в процессе выполнения алгоритма выполняется направленный поиск решения.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">Один из приемов, который может повысить устойчивость алгоритма при случайном начальном назначении центров, состоит в выполнении неоднократного запуска со случайными начальными значениями и выборе того решения, которое покажет минимум функции критерия. Тем самым можно повысить устойчивость алгоритма по отношению к начальному назначению центров кластеров.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Для визуализации результатов кластеризации здесь используется так называемый «силуэт» результатов, который дает представление о распределении величины, равной отношению разности с</span><span style="font-size: 16.0pt; line-height: 125%;">реднего расстояние до членов ближайшего кластера и среднее расстояние до членов своего кластера, деленного на максимум из этих двух средних. </span><span style="font-size: 16.0pt; line-height: 125%;">Значение силуэта изменяется от –1 до +1. Чем дальше будут образы, находящиеся в соседнем кластере, тем ближе к 1 значение силуэта. </span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: #a020f0;"><img border="0" width="297" height="223" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image099.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image100.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">а)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; б)</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.3. Пример отображения силуэта исходных кластеров и полученных решений (dm=3,Ni=50)</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><b><span style="font-size: 16.0pt; line-height: 125%;">Алгоритмы иерархической кластеризации. </span></b><span style="font-size: 16.0pt; line-height: 125%;">Общая идея этих алгоритмов состоит в последовательном объединении или разъединении групп образов, для которых установлены определенные правила слияния групп или, соответственно, правила расщепления. При достижении заданного количества групп&nbsp; (или необходимого уровня другого критерия) процесс останавливают. При объединении групп процесс называется <b>агломеративной</b> кластеризацией, а при разъединении – <b>дивизимной</b> кластеризацией.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Рассмотрим последовательность разделений <sub><img border="0" width="20" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image051.gif"></sub>&nbsp;образов исходной выборки <sub><img border="0" width="31" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image090.gif"></sub>на <sub><img border="0" width="24" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image048.gif"></sub>&nbsp;групп следующим образом:</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 36.0pt; text-indent: -18.0pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">первое разделение <sub><img border="0" width="27" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image101.gif"></sub>&nbsp;состоит из <sub><img border="0" width="20" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image051.gif"></sub>&nbsp;групп, содержащих по одному образу в каждой;</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 36.0pt; text-indent: -18.0pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">второе разделение <sub><img border="0" width="37" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image102.gif"></sub>&nbsp;состоит из <sub><img border="0" width="44" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image103.gif"></sub>&nbsp;групп, содержащих по одному образу в <sub><img border="0" width="47" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image104.gif"></sub>&nbsp;группах и два образа в одной группе;</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">…</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 36.0pt; text-indent: -18.0pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="15" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image105.gif"></sub>- ое разделение <sub><img border="0" width="47" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image106.gif"></sub>состоит из <sub><img border="0" width="71" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image107.gif"></sub>&nbsp;групп, содержащих&nbsp; один или&nbsp; несколько образов в каждой;</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">...</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 36.0pt; text-indent: -18.0pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="20" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image051.gif"></sub>- ое разделение <sub><img border="0" width="28" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image108.gif"></sub>&nbsp;состоит из одной группы, содержащей&nbsp; <sub><img border="0" width="20" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image051.gif"></sub>&nbsp;образов.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Говорят, что процесс обработки данных находится на <sub><img border="0" width="11" height="19" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image109.gif"></sub>- ом уровне в этой последовательности, если выделенное количество групп (кластеров) <sub><img border="0" width="107" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image110.gif"></sub>. Порядок расположения уровней будем определять в соответствие с их номерами (меньшие номера внизу).</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Очевидно, что подобная последовательность разделений может быть получена как при движении </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">c</span><span style="font-size: 16.0pt; line-height: 125%;">низу вверх путем объединения групп (агломеративное), так и при движении сверху вниз путем расщепления групп (дивизимное). Главная идея организации такого процесса состоит в том, два любых образа на некотором уровне обязательно находятся в одной группе. </span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Если при агломеративной &nbsp;кластеризации два образа попадают на каком-либо уровне в одну группу, то они в ней и останутся на более высоких уровнях. </span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Если при дивизимной &nbsp;кластеризации два образа находятся на каком-либо уровне в одну группу, то они обязательно окажутся в разных группах на более низких уровнях. </span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Такой подход обеспечивает направленный перебор комбинаций при &nbsp;кластеризации образов с постепенным улучшением используемых критериев.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Особенностью иерархических алгоритмов является то, что при их реализации обычно строят полное дерево вложенных кластеров ­– дендрограмму. </span></p>
<p class="MsoBodyTextIndent"><b><span style="font-size: 16.0pt; line-height: 125%;">Агломеративный алгоритм кластеризации (стандартная реализация) по шагам: </span></b></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">1. Устанавливается значение <sub><img border="0" width="57" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image111.gif"></sub>&nbsp;и формируется начальное разбиение на группы (начальная кластеризация) <sub><img border="0" width="27" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image101.gif"></sub>, <sub><img border="0" width="212" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image112.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">2. В цикле для выполненной ранее кластеризации <sub><img border="0" width="51" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image113.gif"></sub>и <sub><img border="0" width="107" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image114.gif"></sub>&nbsp;с использованием заданной функции расстояния групп находится ближайшая пара групп, имеющая <sub><img border="0" width="137" height="39" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image115.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent"><span style="font-size: 16.0pt; line-height: 125%;">3. Проводится слияние выбранных групп <sub><img border="0" width="160" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image116.gif"></sub>, изъятие <sub><img border="0" width="37" height="25" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image117.gif"></sub>&nbsp;из <sub><img border="0" width="51" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image113.gif"></sub>&nbsp;и образование новой кластеризации <sub><img border="0" width="40" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image118.gif"></sub>&nbsp;с соответствующими новыми обозначениями групп и присвоением <sub><img border="0" width="84" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image119.gif"></sub>.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">4. Если <sub><img border="0" width="48" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image120.gif"></sub>&nbsp;(можно <sub><img border="0" width="61" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image121.gif"></sub>, если число классов заранее задано) ­ – останов.</span></p>
<p class="MsoBodyTextIndent" style="text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%;">Принципиальное значение для подобных алгоритмов имеет выбор функции расстояния для определения близости кластеров. Используются различные варианты, к которым относятся следующие функции:</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 0cm; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">расстояние между ближайшими соседями <sub><img border="0" width="273" height="39" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image122.gif"></sub>;</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 0cm; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">расстояние между самыми удаленными соседями <sub><img border="0" width="276" height="39" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image123.gif"></sub>;</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 0cm; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">среднее расстояние между образами кластеров <sub><img border="0" width="320" height="56" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image124.gif"></sub>;</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 0cm; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">расстояние между центрами кластеров <sub><img border="0" width="217" height="33" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image125.gif"></sub>, <sub><img border="0" width="117" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image126.gif"></sub>, <sub><img border="0" width="123" height="55" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image127.gif"></sub>;</span></p>
<p class="MsoBodyTextIndent" style="margin-left: 0cm; text-indent: 42.55pt;"><span style="font-size: 16.0pt; line-height: 125%; font-family: Wingdings;">§<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style="font-size: 16.0pt; line-height: 125%;">расстояние Уорда (минимум соответствует максиму прироста суммы квадратов отклонений до центров кластеров при их объединении <sub><img border="0" width="285" height="57" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image128.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image129.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image130.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">а),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;б)</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.4. Отображение полной дендрограммы при М=3,Ni=5 (а),&nbsp; а также&nbsp; получаемых кластеров при завышенном на единицу значении 'maxclust' (M=3,dm=4,Ni=50)</span></p>
<p class="MsoBodyTextIndent" align="center" style="text-align: center; text-indent: 0cm;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" align="center" style="margin-left: 0cm; text-align: center; text-indent: 0cm; text-autospace: none;"><b><span style="font-size: 16.0pt; line-height: 125%; color: black;">4.<span style="font: 7.0pt 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></b><b><span style="font-size: 16.0pt; line-height: 125%; color: black;">Критерии оценки числа классов и сравнительный анализ алгоритмов кластеризации в условиях неизвестного числа классов</span></b></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">&nbsp;</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Рассмотри, наконец, самую «тяжелую» в задачах кластерного анализа ситуацию, когда число классов неизвестно. Основной подход &nbsp;– последовательное выполнение нескольких &nbsp;кластеризаций &nbsp;с перебором числа порождающих классов </span><span style="font-size: 16.0pt; line-height: 125%;"><sub><img border="0" width="24" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image131.gif"></sub>. В итоге осуществляется <span style="color: black;">выбор того варианта с оценкой числа классов, который является наилучшим по определенному критерию. При оценке числа классов по результатам выполнения нескольких вариантов кластеризации с переменным значением </span><sub><img border="0" width="24" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image131.gif"></sub>могут с различным успехом использоваться несколько критериев оптимальности кластеризации. </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">1. Критерий (индекс) Калинского - Харабаша. Основан на максимизации отношения показателей межклассового и внутриклассового разброса<span style="color: #555555;"> при переборе нескольких кластеризаций</span>. Рассчитывается с использованием ранее веденных показателей ВР и МР по следующей формуле:</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="243" height="57" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image132.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">2.</span><span style="font-size: 16.0pt; line-height: 125%;"> Критерий (индекс) Хржановского – Лаи. Основан на выявлении максимального скачка ВР при последовательном изменении числа классов. Рассчитывается по следующей формуле:</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="608" height="57" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image133.gif"></sub>.</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">3.</span><span style="font-size: 16.0pt; line-height: 125%;"> Критерий (индекс) Дэвиса - Болдуина. При его вычислении определяют среднюю схожесть между каждым кластером и наиболее близким ему кластером. На каждом шаге изменения <sub><img border="0" width="24" height="23" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image131.gif"></sub>&nbsp;проводятся вычисления степени схожести образов в каждом кластере и степени различия между кластерами в целом: </span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="208" height="61" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image134.gif"></sub>,<sub><img border="0" width="179" height="51" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image135.gif"></sub>.</span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">При вычислении этих показателей в стандартном варианте используется Евклидово расстояние. В итоге индекс вычисляется по формуле:</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="243" height="48" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image136.gif"></sub>,&nbsp;&nbsp; <sub><img border="0" width="139" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image137.gif"></sub>,</span></p>
<p class="noindent" style="margin: 0cm; margin-bottom: .0001pt; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">где<sub><img border="0" width="23" height="28" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image138.gif"></sub> – мера схожести двух кластеров.</span></p>
<p class="noindent" style="margin: 0cm; margin-bottom: .0001pt; text-align: justify; text-indent: 42.55pt; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">4. Индекс </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%; color: #555555;">GAP</span><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">. Основан на анализе статистики расхождений (ga</span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%; color: #555555;">p</span><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"> – расхождение, зазор, скачок) между вычисленным значением ВР <sub><img border="0" width="103" height="29" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image139.gif"></sub>&nbsp;и усредненными значениями этой же величины, полученными при кластеризации унифицированных выборок, сгенерированных методом Монте-Карло на основе некоторого стандартного распределения</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; text-indent: 42.55pt; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="383" height="47" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image140.gif"></sub>.</span></p>
<p class="noindent" style="margin: 0cm; margin-bottom: .0001pt; text-align: justify; text-indent: 42.55pt; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">Особенностью данного показателя является возможность вычисления даже в случае одного кластера. </span></p>
<p class="noindent" style="margin: 0cm; margin-bottom: .0001pt; text-align: justify; text-indent: 35.45pt; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">5. Индекс оценки силуэта. Основан на вычислении величины «силуэта» для каждого образа, который определяет, насколько этот образ схож с образами собственного кластера, и, как он отличается от образов других кластеров. Индивидуальный индекс силуэта для образа <sub><img border="0" width="87" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image141.gif"></sub>рассчитывается как отношение&nbsp; вида</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="229" height="27" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image142.gif"></sub>, </span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="208" height="52" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image143.gif"></sub>,&nbsp;&nbsp;&nbsp; <sub><img border="0" width="233" height="60" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image144.gif"></sub>,</span></p>
<p class="noindent" style="margin: 0cm; margin-bottom: .0001pt; text-align: justify; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">где <sub><img border="0" width="28" height="27" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image145.gif"></sub>&nbsp;среднее расстояние от <sub><img border="0" width="36" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image146.gif"></sub>&nbsp;до образов своего класса; <sub><img border="0" width="28" height="27" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image147.gif"></sub>&nbsp;минимальное среднее расстояние от <sub><img border="0" width="36" height="24" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image146.gif"></sub>&nbsp;до образов других классов. В итоге вычисляется суммарный силуэт, максимальное значение которого при переборе нескольких кластеризаций дает оценку числа классов: </span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;"><sub><img border="0" width="329" height="47" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image148.gif"></sub>.</span></p>
<p class="noindent" align="center" style="margin: 0cm; margin-bottom: .0001pt; text-align: center; line-height: 125%; background: white;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">&nbsp;</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">На рис.5а,б приведены зависимости частости ошибок при оценке числа классов от величины dm для двух типов алгоритмов кластеризации, используемых при переборе гипотез относительно числа классов. Зависимости на рис.5а,b представлены</span><span style="font-size: 16.0pt; line-height: 125%;"> при <sub><img border="0" width="43" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image052.gif"></sub>&nbsp;</span><span style="font-size: 16.0pt; line-height: 125%;">для величины Ni=50</span><span style="font-size: 16.0pt; line-height: 125%;">, определяющей минимальный объем образов, генерируемых для каждого порождающего класса. <span style="color: black;">Из приведенных графиков видно, что лучшие в данном примере результаты показывают критерий Дэвиса – Болдуина и индекс силуэта. При этом более эффективным является использование указанных показателей совместно с алгоритмом кластеризации К- means&nbsp; (K-внутригрупповых средних). В этом случае пороговое значение величины dm, при котором уровень ошибки становится меньше 5%, будет меньше почти на единицу.</span></span></p>
<table class="MsoNormalTable" border="0" cellpadding="0">
<tbody>
<tr>
<td style="padding: .75pt .75pt .75pt .75pt;">
<p class="MsoNormal" align="center" style="text-align: center;"><span style="font-size: 16.0pt; line-height: 125%; color: #555555;">&nbsp;</span></p>
</td>
</tr>
</tbody>
</table>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image149.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image150.jpg"></span></p>
<p class="MsoNormal" align="left" style="text-align: left; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; а)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;б)</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.5. Зависимости для частости ошибок при использовании различных критериев оценки числа классов &nbsp;</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">&nbsp;</span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">На рис.6. представлены результаты моделирования трех типов ранее рассмотренных алгоритмов кластеризации Cluster with Gaussian Mixtures (EM - алгоритм), k-Means Clustering, Hierarchical Clustering и оценивается качество их работы при не известном заранее числе порождающих классов. При этом сначала проводится оценка числа классов на основе одного из представленных критериев (в примере на&nbsp; основе критерия Девиса – Болдуина), а затем полученная оценка подставляется как входной параметр алгоритм кластеризации. При проведении моделирования рассматривался вариант задания исходных данных, определяющих конфигурацию кластеров, &nbsp;для <sub><img border="0" width="43" height="20" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image052.gif"></sub>. Случайным образом проводилась генерация от 2 до 7 порождающих классов с центрами, расположенными в точках, отличающихся координатами по первым двум признакам на величину dm.</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image151.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image152.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">а)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">б)</span><span style="font-size: 16.0pt; line-height: 125%;"> </span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image153.jpg"><img border="0" width="291" height="218" src="https://edu.vsu.ru/pluginfile.php/947875/mod_book/chapter/15216/v12.files/image154.jpg"></span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-indent: 0cm; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">в)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;г)</span></p>
<p class="MsoNormal" align="center" style="text-align: center; text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Рис.6. &nbsp;Типовые зависимости для частости ошибок при моделировании вариантов совместного применения алгоритмов оценки числа классов и окончательной кластеризации </span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%;">Из трех используемых алгоритмов в примере, представленном на рис.6, на этапе окончательной кластеризации при малых и средних значениях параметра dm наилучшие результаты показывает </span><span lang="EN-US" style="font-size: 16.0pt; line-height: 125%;">EM</span><span style="font-size: 16.0pt; line-height: 125%;">-алгоритм. Ему незначительно уступает алгоритм&nbsp; K - средних. Алгоритм иерархической кластеризации ('linkage') проигрывает им при малых и средних значениях dm, но устойчиво показывает лучшие результаты при высокой степени разделимости классов (когда dm больше 4). <span style="color: black;">Таким образом, мы видим, что задача кластерного анализа при неизвестном числе классов имеет неоднозначное решение с точки зрения выбора используемых алгоритмов и рекомендаций по их настройкам. Это определяет исключительную важность исследований, направленных на моделирование и сравнительный анализ альтернативных вариантов используемых методов и алгоритмов кластеризации применительно к конкретным ситуациям. </span></span></p>
<p class="MsoNormal" style="text-autospace: none;"><span style="font-size: 16.0pt; line-height: 125%; color: black;">Подобный вывод можно сделать по отношению к любым из ранее рассмотренных методов и алгоритмов анализа данных. Рассматривая самые разнообразные методы и алгоритмы анализа данных, мы часто обращали внимание на системные характеристики, напрямую влияющие на их качество и возможности практического применения. Напомним, что к этим характеристикам относятся такие, как: точность алгоритма анализа данных (измеряемый уровень допущенных ошибок), вычислительная сложность и быстродействие, устойчивость по отношению к аномальным наблюдениям, способность к обобщению – сохранению уровня допускаемых ошибок для данных, не участвовавших в процессе обучения, сложность настройки параметров алгоритма, наличие программных библиотечных компонентов для его реализации. Учитывая противоречивый характер требований к общей эффективности применяемого алгоритма, вытекающих из необходимости обеспечения указанных качеств и свойств, задача выбора подходящего варианта становится для исследователя и разработчика нетривиальной. Решить ее можно только в ходе проведения масштабных и многофакторных модельных экспериментов, выполняемых для «пилотных» вариантов алгоритмов, с применением для этих целей современных инструментальных средств компьютерного моделирования</span></p>
</div></div></div><div class="navbottom py-3 border-bottom clearfix navimages"><a title="Закрыть книгу" class="bookexit" href="https://edu.vsu.ru/course/view.php?id=3401#section-6"><i class="icon fa fa-arrow-up fa-fw " title="Закрыть книгу" aria-label="Закрыть книгу"></i></a></div></div>
                    <div class="mt-5 mb-1 activity-navigation container-fluid">
<div class="row">
    <div class="col-md-4">        <div class="float-left">
                <a href="https://edu.vsu.ru/mod/book/view.php?id=58019&amp;forceview=1" id="prev-activity-link" class="btn btn-link" title="Лекция 11">◄ Лекция 11</a>

        </div>
</div>
    <div class="col-md-4">        <div class="mdl-align">
            <div class="urlselect">
    <form method="post" action="https://edu.vsu.ru/course/jumpto.php" class="form-inline" id="url_select_f61e07a8f47d1540">
        <input type="hidden" name="sesskey" value="SGxlcoIBzn">
            <label for="jump-to-activity" class="sr-only">
                Перейти на...
            </label>
        <select id="jump-to-activity" class="custom-select urlselect" name="jump">
                    <option value="" selected="">Перейти на...</option>
                    <option value="/mod/url/view.php?id=802704&amp;forceview=1">Ссылка на вход в лекцию</option>
                    <option value="/mod/attendance/view.php?id=756904&amp;forceview=1">Общая посещаемость ТОИ</option>
                    <option value="/mod/quiz/view.php?id=397565&amp;forceview=1">Экзамен первый вопрос</option>
                    <option value="/mod/quiz/view.php?id=400858&amp;forceview=1">Экзамен второй вопрос</option>
                    <option value="/mod/quiz/view.php?id=883978&amp;forceview=1">Экзамен третий вопрос</option>
                    <option value="/mod/assign/view.php?id=885785&amp;forceview=1">Тексты программ 1 группа 14.01.22</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=504386&amp;forceview=1">ТОИ пересдача лабораторных</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=406372&amp;forceview=1">Консультация к экзамену</option>
                    <option value="/mod/folder/view.php?id=414772&amp;forceview=1">Ведомости для информирования студентов о результатах экзаменов</option>
                    <option value="/mod/forum/view.php?id=57928&amp;forceview=1">Объявления</option>
                    <option value="/mod/page/view.php?id=57975&amp;forceview=1">Цели и задачи учебной дисциплины</option>
                    <option value="/mod/page/view.php?id=57976&amp;forceview=1">Место учебной дисциплины в структуре ООП</option>
                    <option value="/mod/page/view.php?id=57978&amp;forceview=1">Перечень компетенций с указанием этапов формирования и планируемых результатов обучения</option>
                    <option value="/mod/page/view.php?id=57979&amp;forceview=1">Перечень основной и дополнительной литературы, ресурсов интернет, необходимых для освоения дисциплины </option>
                    <option value="/mod/page/view.php?id=57980&amp;forceview=1">Перечень учебно-методического обеспечения для самостоятельной работы</option>
                    <option value="/mod/page/view.php?id=57981&amp;forceview=1">Критерии оценивания компетенций и шкала оценок на экзамене</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=202927&amp;forceview=1">Лекция по теме 1 (06.09-13.09)</option>
                    <option value="/mod/resource/view.php?id=57932&amp;forceview=1">Материалы к лекции по теме 1</option>
                    <option value="/mod/folder/view.php?id=205645&amp;forceview=1">Посещаемость 06.09.21</option>
                    <option value="/mod/folder/view.php?id=620766&amp;forceview=1">Посещаемость 13.09.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=202938&amp;forceview=1">Лекция  "Случайные величины и случайные векторы"</option>
                    <option value="/mod/resource/view.php?id=209042&amp;forceview=1">Материалв к лекции "Случайные величины и случайные векторы"</option>
                    <option value="/mod/folder/view.php?id=209051&amp;forceview=1">Посещаемость 20.09.20</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=209055&amp;forceview=1">Лекция "Байесовская теория принятия решений  </option>
                    <option value="/mod/resource/view.php?id=218308&amp;forceview=1">Материалы к лекции "Байесовская теория принятия решений"</option>
                    <option value="/mod/folder/view.php?id=213630&amp;forceview=1">Посещаемость 27.09.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=218300&amp;forceview=1">Лекция "Распознавание образов, описываемых гауссовскими моделями</option>
                    <option value="/mod/resource/view.php?id=404430&amp;forceview=1">Материалы к лекции "Распознавание образов, описываемых гауссовскими моделями данных"</option>
                    <option value="/mod/folder/view.php?id=222581&amp;forceview=1">Посещаемость 04.10.21-11.10.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=222586&amp;forceview=1">Лекция "Распознавание образов для произвольных распределений"</option>
                    <option value="/mod/resource/view.php?id=227099&amp;forceview=1">Материалы к лекции "Распознавание образов с произвольным распределением"</option>
                    <option value="/mod/folder/view.php?id=227106&amp;forceview=1">Посещаемость 18.10.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=227109&amp;forceview=1">Лекция  Распознавание образов. Параметрическая неопределенность</option>
                    <option value="/mod/resource/view.php?id=235838&amp;forceview=1">Материалы к лекции "Распознавание образов. Параметрическая неопределенность""</option>
                    <option value="/mod/url/view.php?id=698046&amp;forceview=1">Запись лекции 25.10.21</option>
                    <option value="/mod/folder/view.php?id=235846&amp;forceview=1">Посещаемость 25.10.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=245900&amp;forceview=1">Распознавание образов. Непараметрическая неопределенность.</option>
                    <option value="/mod/url/view.php?id=720235&amp;forceview=1">Запись лекции 01.11.21</option>
                    <option value="/mod/resource/view.php?id=254928&amp;forceview=1">Материалы к лекциям "Распознавание образов. Непараметрическая неопределенность" </option>
                    <option value="/mod/folder/view.php?id=246161&amp;forceview=1">Посещаемость 01.11.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=254610&amp;forceview=1">Лекция "Непараметрическая неопределенность. Метод k соседей"</option>
                    <option value="/mod/url/view.php?id=731874&amp;forceview=1">Запись лекции 08.11.21</option>
                    <option value="/mod/folder/view.php?id=254945&amp;forceview=1">Посещаемость 08.11.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=263890&amp;forceview=1">Лекция "Распознавание образов по функции расстояния"</option>
                    <option value="/mod/resource/view.php?id=264605&amp;forceview=1">Материалы к лекции "Распознавание образов по функции расстояния"</option>
                    <option value="/mod/folder/view.php?id=264620&amp;forceview=1">Посещаемость 15.11.21</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=280102&amp;forceview=1">Лекция "Нелинейные спрямляющие преобразования"</option>
                    <option value="/mod/url/view.php?id=780986&amp;forceview=1">Ссылка на запись лекции 22.11.21</option>
                    <option value="/mod/resource/view.php?id=280494&amp;forceview=1">Материалы к лекции "Нелинейные  спрямляющие пространства"</option>
                    <option value="/mod/folder/view.php?id=280509&amp;forceview=1">Посещаемость 22.11.2021</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=802093&amp;forceview=1">Лекция "Метод опорных векторов"</option>
                    <option value="/mod/url/view.php?id=802111&amp;forceview=1">Ссылка на запись лекции 29.11.21 </option>
                    <option value="/mod/resource/view.php?id=304323&amp;forceview=1">Материалы к лекции "Метод опорных векторов"</option>
                    <option value="/mod/folder/view.php?id=304340&amp;forceview=1">Посещаемость 29.11.2021</option>
                    <option value="/mod/folder/view.php?id=329549&amp;forceview=1">Посещаемость 08.12.2020</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=354083&amp;forceview=1">Лекция "Композиционные алгоритмы"</option>
                    <option value="/mod/url/view.php?id=823900&amp;forceview=1">Ссылка на запись лекции 06.12.21</option>
                    <option value="/mod/url/view.php?id=863301&amp;forceview=1">Ссылка на запись лекции 13.12.21 (копия)</option>
                    <option value="/mod/resource/view.php?id=354731&amp;forceview=1">Материалы к лекции "Композиционные алгоритмы"</option>
                    <option value="/mod/folder/view.php?id=354780&amp;forceview=1">Посещаемость 06.12.2021</option>
                    <option value="/mod/folder/view.php?id=380972&amp;forceview=1">Посещаемость13.12.2021</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=399431&amp;forceview=1">Лекция "Основы кластерного анализа данных"</option>
                    <option value="/mod/url/view.php?id=844760&amp;forceview=1">Ссылка на запись лекции 20.12.21</option>
                    <option value="/mod/resource/view.php?id=399927&amp;forceview=1">Материалы к лекции "основы кластерного анализа"</option>
                    <option value="/mod/folder/view.php?id=399950&amp;forceview=1">Посещаемость 20.12.2021</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=877316&amp;forceview=1">Лекция "Основы регрессионного анализа данных" </option>
                    <option value="/mod/url/view.php?id=877339&amp;forceview=1">Ссылка на запись лекции 20.12.27 </option>
                    <option value="/mod/resource/view.php?id=877319&amp;forceview=1">Материалы к лекции "Основы регрессионного  анализа" </option>
                    <option value="/mod/folder/view.php?id=877342&amp;forceview=1">Посещаемость 27.12.2027</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=203532&amp;forceview=1">Лабораторная работа</option>
                    <option value="/mod/bigbluebuttonbn/view.php?id=679704&amp;forceview=1">Лабораторная (группы Акимова А.В.)</option>
                    <option value="/mod/resource/view.php?id=203864&amp;forceview=1">Лабораторная работа 1 -  Моделирование случайных величин</option>
                    <option value="/mod/resource/view.php?id=203869&amp;forceview=1">Пример кода лабораторной работы 1</option>
                    <option value="/mod/url/view.php?id=229156&amp;forceview=1">Посещаемость лабораторных занятий группами Акимова А.В.</option>
                    <option value="/mod/url/view.php?id=209992&amp;forceview=1">Варианты для групп Акимова А.В.</option>
                    <option value="/mod/resource/view.php?id=680450&amp;forceview=1">Варианты на 4,5 лабы для гр.2-2</option>
                    <option value="/mod/assign/view.php?id=206869&amp;forceview=1">Лабораторная работа 1</option>
                    <option value="/mod/assign/view.php?id=206873&amp;forceview=1">Лабораторная работа 2</option>
                    <option value="/mod/assign/view.php?id=206876&amp;forceview=1">Лабораторная работа 3</option>
                    <option value="/mod/assign/view.php?id=206880&amp;forceview=1">Лабораторная работа 4</option>
                    <option value="/mod/url/view.php?id=690053&amp;forceview=1">Лабораторная 4 (Видеозапись от 22.10.2021)</option>
                    <option value="/mod/assign/view.php?id=206884&amp;forceview=1">Лабораторная работа 5</option>
                    <option value="/mod/assign/view.php?id=206885&amp;forceview=1">Лабораторная работа 6</option>
                    <option value="/mod/url/view.php?id=796107&amp;forceview=1">Лабораторная 6 (Видеозапись от 16.11.2021)</option>
                    <option value="/mod/assign/view.php?id=206889&amp;forceview=1">Лабораторная работа 7</option>
                    <option value="/mod/assign/view.php?id=206896&amp;forceview=1">Лабораторная работа 8</option>
                    <option value="/mod/assign/view.php?id=206897&amp;forceview=1">Лабораторная работа 9</option>
                    <option value="/mod/resource/view.php?id=765836&amp;forceview=1">Список сданных лаб</option>
                    <option value="/mod/book/view.php?id=57930&amp;forceview=1">Лекция 2</option>
                    <option value="/mod/book/view.php?id=57941&amp;forceview=1">Лекция 3</option>
                    <option value="/mod/book/view.php?id=57939&amp;forceview=1">Лекция 4</option>
                    <option value="/mod/book/view.php?id=57942&amp;forceview=1">Лекция 5</option>
                    <option value="/mod/book/view.php?id=57943&amp;forceview=1">Лекция 6</option>
                    <option value="/mod/book/view.php?id=57944&amp;forceview=1">Лекция 7</option>
                    <option value="/mod/book/view.php?id=57945&amp;forceview=1">Лекция 8</option>
                    <option value="/mod/book/view.php?id=57946&amp;forceview=1">Лекция 9</option>
                    <option value="/mod/book/view.php?id=58016&amp;forceview=1">Лекция 10</option>
                    <option value="/mod/book/view.php?id=58019&amp;forceview=1">Лекция 11</option>
                    <option value="/mod/book/view.php?id=58093&amp;forceview=1">Лекция 13</option>
        </select>
            <noscript>
                <input type="submit" class="btn btn-secondary ml-1" value="Применить">
            </noscript>
    </form>
</div>

        </div>
</div>
    <div class="col-md-4">        <div class="float-right">
                <a href="https://edu.vsu.ru/mod/book/view.php?id=58093&amp;forceview=1" id="next-activity-link" class="btn btn-link" title="Лекция 13">Лекция 13 ►</a>

        </div>
</div>
</div>
</div>
                    
                