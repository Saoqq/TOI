# 16 - Метод опорных векторов для случая линейно разделимых классов
описать, как для нескольких классов (стр. 13)

## ![scheme](метод%20опорных%20векторов%20для%20случая%20линейно%20разделимых%20классов.png)

1) Входные данные:
- смешанная индексированная выборка $X^N=\{x^{(1)},...,x^{(N)}\},\\  
D^N = \{d^{(1)},...,d^{(N)}\},
\begin{array}{l}
d^{(*)}=1,x^{(*)}\in \omega_1\\
d^{(*)}=-1,x^{(*)}\in \omega_2
\end{array}
$
- образ $x$, который необходимо распознать.
2) В рамках данного подхода ищется гиперплоскость, которая находится на максимальной расстоянии от ближайших к ней граничных точек обоих классов.  
Предполагается, что существует линейно разделяющая функция, которая равна нулю во всех точках, лежащих на поверхности этой гиперплоскости:  
$g(x) = x^T\omega-b_0$.  
Для удобства ??? вектора $\omega$ и величины $b_0$ проводят нормировку так, чтобы:
$
\def\arraystretch{0.6}
\begin{array}{c}
\small min\\
\small i
\end{array}
d^{(i)}(x^{(i)T}\omega-b_0)=1
$.  
В каждом классе нужно ??? такие точки, чтобы между ними не лежала ни одна точка из обучающей выборки и чтобы расстояние между ними (ширина разделяющей полосы $\triangle$) было максимальным. Эти точки соответствуют опорным векторам.  
$\triangle = \frac2{||\omega||}$
Необходимо ??? 
$
\def\arraystretch{0.6}
\begin{array}{c}
\small max\\
\small \omega
\end{array}
\triangle
$
для системы неравенств - ограничений:
    $$
    d^{(i)}g(x^{(i)}) = d^{(i)}(x^{(i)T}\omega - b_0) \geq 1, i=\overline{1,N},
    $$
    ## дальше формулы со стр. 4-5 лекции 10.
    Сформулируем как задачу квадратичного программирования с ограничениями-неравенствами:
    $$
    \left\{
    \begin{array}{l}
    \frac12\omega^T\omega \rightarrow min,\\
    d^{(i)}(x^{(i)T}\omega -b_0) \geq 1, i=\overline{1,N}
    \end{array}
    \right.
    $$  
    В соответствии с теоремой Куна - Таккера задача эквивалентна двойственной задаче поиска седловой точки функции Лагранжа:
    $$
    \left\{
    \begin{array}{l}
    L(\omega,b_0,\lambda) = \frac12\omega^T\omega-\sum_{i=1}^{N}\lambda_i[d^{(i)}(x^{(i)T}\omega-b_0)-1]\rightarrow 
    \def\arraystretch{0.6}
    \begin{array}{c}
    \small min\\
    \small \omega, b_0
    \end{array}
    \begin{array}{c}
    \small max\\
    \small \lambda
    \end{array}, \\
    \lambda_i \geq 0, i=\overline{1,N},\\
    \lambda_i=0 \ или \  d^{(i)}(x^{(i)T}\omega -b_0) \geq 1, i=\overline{1,N},
    \end{array}
    \right.
    $$  
    где $\lambda=(\lambda_1,...,\lambda_N)^T$ - вектор переменных, двойственных к ограничению $d^{(i)}g(x{(i)}) \geq 1$ (множители Лагранжа).  
    Необходимым условием седловой точки функции Лагранжа является равенство нулю ее производных:
    $$
    \frac{\partial L}{\partial \omega} = \omega - \sum_{i=1}^{N}\lambda_id^{(i)}x^{(i)}=0, \frac{\partial L}{\partial b_0} = - \sum_{i=1}^{N}\lambda_id^{(i)}=0.
    $$  
    Отсюда, вектор весовых коэффициентов $\omega$ является линейной комбинацией элементов обучающей выборки, причем тех, для которых $\lambda_i > 0$.
    $$
    \omega = \sum_{i=1}^{N}\lambda_id^{(i)}x^{(i)}.
    $$  
    Эти векторы (для которых $\lambda_i>0$) и есть **опорные**.  
    Чтобы найти $b_0$ нужно найти $\omega$ на основе формулы выше и для произвольного граничного вектора выразить $b_0$ из равенства
    $$
    b_0=x^{(i)T}\omega-d^{(i)}, \lambda_i>0.
    $$  
    На практике для повышения устойчивости рекомендуется брать медиану множества значений $b_0$, вычисленных по всем граничным опорным векторам.
    $$
    b_0 = med\{x^{(i)}\omega-d^{(i)},\lambda_i>0 \}
    $$

3) Решение в пользу одного из двух классов принимается на основании разделяющей функции:
$$
g'(x)= sign(x^T\omega - b_0) = sign(\sum_{i=1}^{N}\lambda_i d^{(i)}x^Tx^{(i)}-b_0) 
$$